{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73384226",
   "metadata": {},
   "source": [
    "# **Handling Imbalanced Dataset**\n",
    "\n",
    "## Overview\n",
    "When working with imbalanced datasets, the classes are not equally distributed, which can lead to biased models.\n",
    "\n",
    "#### Handling Imbalanced Data\n",
    "\n",
    "**Two main approaches:**\n",
    "\n",
    "1. **Downsampling**\n",
    "    - Reduce majority class samples\n",
    "    - Example: 1000 datapoints with 900 Yes and 100 No\n",
    "    - Balance ratio: 900:100 = 9:1\n",
    "    - After downsampling: 100 Yes to 100 No → 1:1 ratio\n",
    "\n",
    "2. **Upsampling**\n",
    "    - Increase minority class samples\n",
    "    - Useful when you cannot afford to lose majority class data\n",
    "\n",
    "## Example \n",
    "\n",
    "### Binary Classification → Class Distribution (Yes/No)\n",
    "- Total datapoints: 1000\n",
    "- Yes: 900\n",
    "- No: 100\n",
    "- Imbalance Ratio: 9:1\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Start with imbalanced dataset (1000 datapoints)\n",
    "2. Apply sampling technique (downsampling or upsampling)\n",
    "3. Train your model on balanced data\n",
    "4. Evaluate on test set with original distribution\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: The choice between downsampling and upsampling depends on:\n",
    "- Dataset size\n",
    "- Computational resources\n",
    "- Whether losing data is acceptable\n",
    "- Class importance in your use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342fc3a",
   "metadata": {},
   "source": [
    "## Creating Synthetic Samples\n",
    "\n",
    "imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d65025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42) # For reproducibility ==> so that random operations yield the same results each time the code is run.\n",
    "\n",
    "# Dataframe with two classes: 'A' (majority) and 'B' (minority)\n",
    "n_samples = 1000\n",
    "class_A_Ratio = 0.9\n",
    "n_class_A = int(n_samples * class_A_Ratio)\n",
    "n_class_B = n_samples - n_class_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245e3bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_A , n_class_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2826ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "feature_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "fdaab729-f925-4849-bfaa-1ae2ace02578",
       "rows": [
        [
         "0",
         "-0.863493604964934",
         "-0.3918767653868664",
         "0"
        ],
        [
         "1",
         "-0.031203488939083975",
         "-1.017764309076953",
         "0"
        ],
        [
         "2",
         "0.018016872044446585",
         "-1.027403551526011",
         "0"
        ],
        [
         "3",
         "0.47263034584340563",
         "-0.3732682459413141",
         "0"
        ],
        [
         "4",
         "-1.3668583632808264",
         "0.6445184916452914",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.863494</td>\n",
       "      <td>-0.391877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.031203</td>\n",
       "      <td>-1.017764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018017</td>\n",
       "      <td>-1.027404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.472630</td>\n",
       "      <td>-0.373268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.366858</td>\n",
       "      <td>0.644518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  target\n",
       "0  -0.863494  -0.391877       0\n",
       "1  -0.031203  -1.017764       0\n",
       "2   0.018017  -1.027404       0\n",
       "3   0.472630  -0.373268       0\n",
       "4  -1.366858   0.644518       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_A = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc=0, scale=1, size=n_class_A),\n",
    "    'feature_2': np.random.normal(loc=0, scale=1, size=n_class_A),\n",
    "    'target': [0] * n_class_A\n",
    "})\n",
    "\n",
    "class_B = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc=2, scale=1, size=n_class_B),\n",
    "    'feature_2': np.random.normal(loc=2, scale=1, size=n_class_B),\n",
    "    'target': [1] * n_class_B\n",
    "})\n",
    "\n",
    "# Combine both classes to create imbalanced dataset\n",
    "\n",
    "# method 1\n",
    "imbalanced_df = pd.concat([class_A, class_B], ignore_index=True)    # ignore_index=True is used to reset the index of the combined DataFrame.\n",
    "# method 2\n",
    "# imbalanced_df = pd.concat([class_A, class_B]).reset_index(drop=True)    # reset_index(drop=True) is used to reset the index of the combined DataFrame, dropping the old index.\n",
    "\n",
    "\n",
    "imbalanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8c3cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7d547365-3474-4840-996f-ca13e96b1b5c",
       "rows": [
        [
         "0",
         "900"
        ],
        [
         "1",
         "100"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imbalanced_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754ac50",
   "metadata": {},
   "source": [
    "## **Upsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed1e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = imbalanced_df[imbalanced_df['target'] == 0]\n",
    "df_minority = imbalanced_df[imbalanced_df['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fa2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample      \n",
    "# resample is a utility function from scikit-learn that allows for easy upsampling or downsampling of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91989a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "Upsampled_minority = resample(df_minority, replace=True,    # sample with replacement => allows the same data point to be selected multiple times.\n",
    "                                n_samples=len(df_majority),    # match number of majority class\n",
    "                                random_state=42)    # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61beace2",
   "metadata": {},
   "source": [
    "So , we have increased the number of samples in the minority class by randomly duplicating existing samples until both classes have equal representation.\n",
    "\n",
    "Now let's check the shape of the upsampled minority class to confirm the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46b0a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Upsampled_minority.shape       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1197ad",
   "metadata": {},
   "source": [
    "Concatenate the upsampled minority class with the original majority class to create a new balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df_majority, Upsampled_minority], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9aafde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5dbf206d-5715-4748-bb19-3d5239f50234",
       "rows": [
        [
         "0",
         "900"
        ],
        [
         "1",
         "900"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e4d33",
   "metadata": {},
   "source": [
    "## Creating Synthetic samples\n",
    "\n",
    "`Same code as above`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61aa3a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "41e7fece-1070-416f-80ef-edb22afd8ea1",
       "rows": [
        [
         "0",
         "900"
        ],
        [
         "1",
         "100"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42) # For reproducibility ==> so that random operations yield the same results each time the code is run.\n",
    "\n",
    "# Dataframe with two classes: 'A' (majority) and 'B' (minority)\n",
    "n_samples = 1000\n",
    "class_A_Ratio = 0.9\n",
    "n_class_A = int(n_samples * class_A_Ratio)\n",
    "n_class_B = n_samples - n_class_A\n",
    "\n",
    "class_A = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc=0, scale=1, size=n_class_A),\n",
    "    'feature_2': np.random.normal(loc=0, scale=1, size=n_class_A),\n",
    "    'target': [0] * n_class_A\n",
    "})\n",
    "\n",
    "class_B = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc=2, scale=1, size=n_class_B),\n",
    "    'feature_2': np.random.normal(loc=2, scale=1, size=n_class_B),\n",
    "    'target': [1] * n_class_B\n",
    "})\n",
    "\n",
    "# Combine both classes to create imbalanced dataset\n",
    "\n",
    "# method 1\n",
    "imbalanced_df = pd.concat([class_A, class_B], ignore_index=True)    # ignore_index=True is used to reset the index of the combined DataFrame.\n",
    "# method 2\n",
    "# imbalanced_df = pd.concat([class_A, class_B]).reset_index(drop=True)    # reset_index(drop=True) is used to reset the index of the combined DataFrame, dropping the old index.\n",
    "\n",
    "\n",
    "imbalanced_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eb5bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = imbalanced_df[imbalanced_df['target'] == 0]\n",
    "df_minority = imbalanced_df[imbalanced_df['target'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a737412",
   "metadata": {},
   "source": [
    "## **Downsampling**\n",
    "\n",
    "`It is considered bad because we are losing valuable data from the majority class which might contain important patterns and information that could help the model learn better .`\n",
    "\n",
    "- but in some cases when the dataset is very large and computational resources are limited , downsampling can be a practical approach to quickly balance the classes without significantly impacting model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b07d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample      \n",
    "# resample is a utility function from scikit-learn that allows for easy upsampling or downsampling of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3206d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Downsampled_majority = resample(df_majority, replace=False,    # sample with replacement is False  => Because we want to reduce the data points .\n",
    "                                n_samples=len(df_minority),    # match number of minority class\n",
    "                                random_state=42)    # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c00eb1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Downsampled_majority.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b66f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_Downsampled = pd.concat([df_minority, Downsampled_majority], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f518803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5e18351d-1b50-4da5-94e1-bea3280e42bb",
       "rows": [
        [
         "1",
         "100"
        ],
        [
         "0",
         "100"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "1    100\n",
       "0    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_Downsampled['target'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
